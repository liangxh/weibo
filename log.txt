# Research Log
Xihao Liang, 2016.02.15

---

## Procedure

1. 篩選出僅包含一種表情符, 文字非空, 評論非空的微博, 得出不同表情符對應的微博 mid (statica.collect_emo_mids > emo_mids.pkl)
2. 统计出不同表情符的覆蓋率 (statica.analyse_emo_mids)
3. 把emo_mids.pkl拆出子文件方便讀取 (statica.split_emo_mids > eid_mids/$EID.txt)
4. 得出不同emo 對應的mids 各自對應的uids (statica.export_uids > eid_uids/$EID.pkl)
5. 對不同eid 對應的微博篩選出4000條微博, 另外透過檢查樣例添加剔除規則 (如除去韓文在等1.中未實現) (sampler.sample(eid))
6. 觀察用戶分布情況 (userdist.py)
7. 為數據集建立字符編碼 (tfcoder.init > dataset/tfcoder.pkl)
8. 建立字符編碼組成的訓練數據 (unidatica.prepare > dataset/unidata.pkl)
8. 字符編碼-LSTM 運行 (lstm.py)
9. 在數據庫中找出數據集中每條微博的上文(該作者的前數條微博) (lastblog.get / lastblog.exists)
10. 檢查HowNet對數據集的覆蓋率 (hntest. not finished)
*. hownet對每一句的覆蓋率
*. 未覆蓋詞檢查

*. 根據篩選出的數據集下載並保存評論 (not done )
	問題:
	數據庫中comments_count > 1不一定能下載到評論 (微博被刪除或廣告評論被新浪自動刪除)

12. 數據重篩選 (添加 有評論 和 有上文 兩個條件)
	問題:
	1) 可能出現EID > 80的數據收集達不到4000, 待測
	2) 判断有無評論涉及爬蟲, 設計中断/继续機制

*. 選擇詞表示方法
*. 人工標注工具開發

## Extra

1. 對樣本集進行分詞 (zhprocessor.segment)
2. 實現基於occurrence matrix的詞向量訓練器 (concept.ConceptClassifier)

---

Created on 2016.02.06
